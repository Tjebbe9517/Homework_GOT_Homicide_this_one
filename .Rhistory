GoT_nrc_n <- GoT_nrc %>%
count(sentiment, sort = TRUE)
# And plot them:
ggplot(data = GoT_nrc_n, aes(x = sentiment, y = n)) +
geom_col()
GoT_nrc_n5 <- GoT_nrc %>%
count(word,sentiment, sort = TRUE) %>%
group_by(sentiment) %>%
top_n(5) %>%
ungroup()
GoT_nrc_gg <- ggplot(data = GoT_nrc_n5, aes(x = reorder(word,n), y = n, fill = sentiment)) +
geom_col(show.legend = FALSE) +
facet_wrap(~sentiment, ncol = 2, scales = "free") +
coord_flip() +
theme_minimal() +
labs(x = "Word", y = "count")
# Show it
GoT_nrc_gg
# Save it
ggsave(plot = ipcc_nrc_gg,
here("figures","ipcc_nrc_sentiment.png"),
height = 8,
width = 5)
GoT_nrc_n5 <- GoT_nrc %>%
count(word,sentiment, sort = TRUE) %>%
group_by(sentiment) %>%
top_n(5) %>%
ungroup()
GoT_nrc_gg <- ggplot(data = GoT_nrc_n5, aes(x = reorder(word,n), y = n, fill = sentiment)) +
geom_col(show.legend = FALSE) +
facet_wrap(~sentiment, ncol = 2, scales = "free") +
coord_flip() +
theme_minimal() +
labs(x = "Word", y = "count")
# Show it
GoT_nrc_gg
# Save it
ggsave(plot = ipcc_nrc_gg,
here("figures","GoT_nrc_sentiment.png"),
height = 8,
width = 5)
GoT_nrc_n5 <- GoT_nrc %>%
count(word,sentiment, sort = TRUE) %>%
group_by(sentiment) %>%
top_n(5) %>%
ungroup()
GoT_nrc_gg <- ggplot(data = GoT_nrc_n5, aes(x = reorder(word,n), y = n, fill = sentiment)) +
geom_col(show.legend = FALSE) +
facet_wrap(~sentiment, ncol = 2, scales = "free") +
coord_flip() +
theme_minimal() +
labs(x = "Word", y = "count")
# Show it
GoT_nrc_gg
# Save it
ggsave(plot = GoT_nrc_gg,
here("figures","GoT_nrc_sentiment.png"),
height = 8,
width = 5)
conf <- get_sentiments(lexicon = "nrc") %>%
filter(word == "confidence")
conf
# Check the unique 2-score words:
unique(GoT_afinn2$word)
# Count & plot them
GoT_afinn2_n <- GoT_afinn2 %>%
count(word, sort = TRUE) %>%
mutate(word = fct_reorder(factor(word), n))
ggplot(data = GoT_afinn2_n, aes(x = word, y = n)) +
geom_col() +
coord_flip()
# Check the unique 2-score words:
unique(GoT_afinn2$word)
# Count & plot them
GoT_afinn2_n <- GoT_afinn2 %>%
count(word, sort = TRUE) %>%
mutate(word = fct_reorder(factor(word), n))
gg_plotting <- GoT_afinn2_n[20:2, 2]
ggplot(data = GoT_afinn2_n, aes(x = word, y = n)) +
geom_col() +
coord_flip()
# Check the unique 2-score words:
unique(GoT_afinn2$word)
# Count & plot them
GoT_afinn2_n <- GoT_afinn2 %>%
count(word, sort = TRUE) %>%
mutate(word = fct_reorder(factor(word), n))
gg_plotting <- GoT_afinn2_n[20:2, 2]
ggplot(data = gg_plotting, aes(x = word, y = n)) +
geom_col() +
coord_flip()
knitr::opts_chunk$set(echo = TRUE,
warning = FALSE,
message = FALSE)
library(tidyverse)
library(here)
# For text mining:
library(pdftools)
library(tidytext)
library(textdata)
library(ggwordcloud)
# Note - Before lab:
# Attach tidytext and textdata packages
# Run: get_sentiments(lexicon = "nrc")
# Should be prompted to install lexicon - choose yes!
# Run: get_sentiments(lexicon = "afinn")
# Should be prompted to install lexicon - choose yes!
get_sentiments(lexicon = "afinn")
# Note: may be prompted to download (yes)
# Let's look at the pretty positive words:
afinn_pos <- get_sentiments("afinn") %>%
filter(value %in% c(3,4,5))
# Do not look at negative words in class.
afinn_pos
ipcc_afinn <- ipcc_stop %>%
inner_join(get_sentiments("afinn"))
knitr::opts_chunk$set(echo = TRUE)
GoT_afinn <- GoT_stop %>%
inner_join(get_sentiments("afinn"))
ipcc_afinn <- ipcc_stop %>%
inner_join(get_sentiments("afinn"))
ipcc_afinn <- ipcc_stop %>%
inner_join(get_sentiments("afinn"))
GoT_afinn <- GoT_stop %>%
inner_join(get_sentiments("afinn"))
ipcc_afinn <- ipcc_stop %>%
inner_join(get_sentiments("afinn"))
GoT_afinn_hist <- GoT_afinn %>%
count(value)
# Plot them:
ggplot(data = GoT_afinn_hist, aes(x = value, y = n)) +
geom_col()
# What are these '2' words?
ipcc_afinn2 <- ipcc_afinn %>%
filter(value == 2)
GoT_afinn2 <- GoT_afinn %>%
filter(value == 2)
# Check the unique 2-score words:
unique(GoT_afinn2$word)
# Count & plot them
GoT_afinn2_n <- GoT_afinn2 %>%
count(word, sort = TRUE) %>%
mutate(word = fct_reorder(factor(word), n))
ggplot(data = GoT_afinn2_n, aes(x = word, y = n)) +
geom_col() +
coord_flip()
unique(ipcc_afinn2$word)
# Count & plot them
GoT_afinn2_n <- GoT_afinn2 %>%
count(word, sort = TRUE) %>%
mutate(word = fct_reorder(factor(word), n))
ggplot(data = GoT_afinn2_n, aes(x = word, y = n)) +
geom_col() +
coord_flip()
GoT_summary <- GoT_afinn %>%
summarize(
mean_score = mean(value),
median_score = median(value)
)
GoT_nrc <- GoT_stop %>%
inner_join(get_sentiments("nrc"))
GoT_exclude <- GoT_stop %>%
anti_join(get_sentiments("nrc"))
# View(GoT_exclude)
# Count to find the most excluded:
GoT_exclude_n <- GoT_exclude %>%
count(word, sort = TRUE)
head(GoT_exclude_n)
ipcc_exclude <- ipcc_stop %>%
anti_join(get_sentiments("nrc"))
# View(ipcc_exclude)
# Count to find the most excluded:
ipcc_exclude_n <- ipcc_exclude %>%
count(word, sort = TRUE)
head(ipcc_exclude_n)
GoT_nrc_n <- GoT_nrc %>%
count(sentiment, sort = TRUE)
# And plot them:
ggplot(data = GoT_nrc_n, aes(x = sentiment, y = n)) +
geom_col()
ipcc_nrc_n5 <- ipcc_nrc %>%
count(word,sentiment, sort = TRUE) %>%
group_by(sentiment) %>%
top_n(5) %>%
ungroup()
GoT_nrc_n5 <- GoT_nrc %>%
count(word,sentiment, sort = TRUE) %>%
group_by(sentiment) %>%
top_n(5) %>%
ungroup()
GoT_nrc_gg <- ggplot(data = GoT_nrc_n5, aes(x = reorder(word,n), y = n, fill = sentiment)) +
geom_col(show.legend = FALSE) +
facet_wrap(~sentiment, ncol = 2, scales = "free") +
coord_flip() +
theme_minimal() +
labs(x = "Word", y = "count")
# Show it
GoT_nrc_gg
# Save it
ggsave(plot = GoT_nrc_gg,
here("figures","GoT_nrc_sentiment.png"),
height = 8,
width = 5)
ipcc_nrc_n5 <- ipcc_nrc %>%
count(word,sentiment, sort = TRUE) %>%
group_by(sentiment) %>%
top_n(5) %>%
ungroup()
conf <- get_sentiments(lexicon = "nrc") %>%
filter(word == "confidence")
conf
unique(ipcc_afinn2$word)
# Count & plot them
GoT_afinn2_n <- GoT_afinn2 %>%
count(word, 1-100 sort = TRUE) %>%
unique(ipcc_afinn2$word)
# Count & plot them
GoT_afinn2_n <- GoT_afinn2 %>%
count(word, sort = TRUE) %>%
mutate(word = fct_reorder(factor(word), n))
ggplot(data = GoT_afinn2_n, aes(x = word, y = n)) +
geom_col() +
coord_flip()
GoT_afinn_minus_4 <- GoT_afinn %>%
filter(value == -4)
unique(ipcc_afinn_minus_4$word)
unique(GoT_afinn_minus_4$word)
# Count & plot them
GoT_afinn_minus_4_n <- GoT_afinn2 %>%
count(word, sort = TRUE) %>%
mutate(word = fct_reorder(factor(word), n))
ggplot(data = GoT_afinn_minus_4_n, aes(x = word, y = n)) +
geom_col() +
coord_flip()
GoT_afinn_minus_4 <- GoT_afinn %>%
filter(value == -4)
unique(GoT_afinn_minus_4$word)
# Count & plot them
GoT_afinn_minus_4_n <- GoT_afinn2 %>%
count(word, sort = TRUE) %>%
mutate(word = fct_reorder(factor(word), n))
ggplot(data = GoT_afinn_minus_4_n, aes(x = word, y = n)) +
geom_col() +
coord_flip()
unique(GoT_afinn_minus_5$word)
GoT_afinn_minus_5 <- GoT_afinn %>%
filter(value == -5)
unique(GoT_afinn_minus_5$word)
# Count & plot them
GoT_afinn_minus_5_n <- GoT_afinn2 %>%
count(word, sort = TRUE) %>%
mutate(word = fct_reorder(factor(word), n))
ggplot(data = GoT_afinn_minus_5_n, aes(x = word, y = n)) +
geom_col() +
coord_flip()
GoT_afinn_minus_5 <- GoT_afinn %>%
filter(value ==-5)
unique(GoT_afinn_minus_5$word)
# Count & plot them
GoT_afinn_minus_5_n <- GoT_afinn2 %>%
count(word, sort = TRUE) %>%
mutate(word = fct_reorder(factor(word), n))
ggplot(data = GoT_afinn_minus_5_n, aes(x = word, y = n)) +
geom_col() +
coord_flip()
unique(GoT_afinn_minus_5$word)
# Count & plot them
GoT_afinn_minus_5_n <- GoT_afinn_minus_5 %>%
count(word, sort = TRUE) %>%
mutate(word = fct_reorder(factor(word), n))
ggplot(data = GoT_afinn_minus_5_n, aes(x = word, y = n)) +
geom_col() +
coord_flip()
GoT_stop <- GoT_tokens %>%
anti_join(stop_words) %>%
select(-GoT_text)
GoT_no_numeric <- GoT_stop %>%
filter(is.na(as.numeric(word)))
GoT_swc <- GoT_stop %>%
count(word) %>%
arrange(-n)
GoT_no_numeric <- GoT_stop %>%
filter(is.na(as.numeric(word)))
GoT_stop <- GoT_tokens %>%
anti_join(stop_words) %>%
select(-GoT_text)
View(stop_words)
knitr::opts_chunk$set(echo = TRUE)
#getting the data
GoT_path <- here("data","got.pdf")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(here)
# For text mining:
library(pdftools)
library(tidytext)
library(textdata)
library(ggwordcloud)
# Note - Before lab:
# Attach tidytext and textdata packages
# Run: get_sentiments(lexicon = "nrc")
# Should be prompted to install lexicon - choose yes!
# Run: get_sentiments(lexicon = "afinn")
# Should be prompted to install lexicon - choose yes!
#getting the data
GoT_path <- here("data","got.pdf")
GoT_text <- pdf_text(GoT_path)
getwd()
#finding page 9
GoT_p9 <- GoT_text[9]
GoT_p9
#getting the data
GoT_path <- here("data","got.pdf")
GoT_text <- pdf_text(GoT_path)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(here)
# For text mining:
library(pdftools)
library(tidytext)
library(textdata)
library(ggwordcloud)
# Note - Before lab:
# Attach tidytext and textdata packages
# Run: get_sentiments(lexicon = "nrc")
# Should be prompted to install lexicon - choose yes!
# Run: get_sentiments(lexicon = "afinn")
# Should be prompted to install lexicon - choose yes!
#getting the data
GoT_path <- here("data","got.pdf")
GoT_text <- pdf_text(GoT_path)
GoT_tokens <- GoT_df %>%
unnest_tokens(word, text_full)
GoT_wc <- GoT_tokens %>%
count(word) %>%
arrange(-n)
GoT_wc
View(stop_words)
knitr::opts_chunk$set(echo = TRUE,
warning = FALSE,
message = FALSE)
library(tidyverse)
library(here)
# For text mining:
library(pdftools)
library(tidytext)
library(textdata)
library(ggwordcloud)
# Note - Before lab:
# Attach tidytext and textdata packages
# Run: get_sentiments(lexicon = "nrc")
# Should be prompted to install lexicon - choose yes!
# Run: get_sentiments(lexicon = "afinn")
# Should be prompted to install lexicon - choose yes!
ipcc_stop <- ipcc_tokens %>%
anti_join(stop_words) %>%
select(-ipcc_text)
ipcc_swc <- ipcc_stop %>%
count(word) %>%
arrange(-n)
ipcc_swc <- ipcc_stop %>%
count(word) %>%
arrange(-n)
# This code will filter out numbers by asking:
# If you convert to as.numeric, is it NA (meaning those words)?
# If it IS NA (is.na), then keep it (so all words are kept)
# Anything that is converted to a number is removed
ipcc_no_numeric <- ipcc_stop %>%
filter(is.na(as.numeric(word)))
# This code will filter out numbers by asking:
# If you convert to as.numeric, is it NA (meaning those words)?
# If it IS NA (is.na), then keep it (so all words are kept)
# Anything that is converted to a number is removed
GoT_no_numeric <- GoT_stop %>%
filter(is.na(as.numeric(word)))
GoT_no_numeric <- GoT_stop %>%
filter(is.na(as.numeric(word)))
GoT_swc <- GoT_stop %>%
count(word) %>%
arrange(-n)
GoT_no_numeric <- GoT_stop %>%
filter(is.na(as.numeric(word)))
GoT_swc <- GoT_stop %>%
count(word) %>%
arrange(-n)
GoT_stop <- GoT_tokens %>%
anti_join(stop_words) %>%
select(-GoT_text)
GoT_swc <- GoT_stop %>%
count(word) %>%
arrange(-n)
GoT_no_numeric <- GoT_stop %>%
filter(is.na(as.numeric(word)))
length(unique(GoT_no_numeric$word))
# We probably don't want to include them all in a word cloud. Let's filter to only include the top 100 most frequent?
GoT_top100 <- GoT_no_numeric %>%
count(word) %>%
arrange(-n) %>%
head(100)
# This code will filter out numbers by asking:
# If you convert to as.numeric, is it NA (meaning those words)?
# If it IS NA (is.na), then keep it (so all words are kept)
# Anything that is converted to a number is removed
ipcc_no_numeric <- ipcc_stop %>%
filter(is.na(as.numeric(word)))
# There are almost 2000 unique words
length(unique(ipcc_no_numeric$word))
# We probably don't want to include them all in a word cloud. Let's filter to only include the top 100 most frequent?
ipcc_top100 <- ipcc_no_numeric %>%
count(word) %>%
arrange(-n) %>%
head(100)
length(unique(GoT_no_numeric$word))
# We probably don't want to include them all in a word cloud. Let's filter to only include the top 100 most frequent?
GoT_top100 <- GoT_no_numeric %>%
count(word) %>%
arrange(-n) %>%
head(100)
#making a word cloud
GoT_cloud <- ggplot(data = GoT_top100, aes(label = word)) +
geom_text_wordcloud() +
theme_minimal()
GoT_cloud
ggplot(data = GoT_top100, aes(label = word, size = n)) +
geom_text_wordcloud_area(aes(color = n), shape = "diamond") +
scale_size_area(max_size = 12) +
scale_color_gradientn(colors = c("darkgreen","blue","red")) +
theme_minimal()
get_sentiments(lexicon = "afinn")
# Note: may be prompted to download (yes)
get_sentiments(lexicon = "afinn")
# Note: may be prompted to download (yes)
afinn_pos <- get_sentiments("afinn") %>%
filter(value %in% c(3,4,5))
get_sentiments(lexicon = "afinn")
# Note: may be prompted to download (yes)
afinn_pos <- get_sentiments("afinn") %>%
filter(value %in% c(3,4,5))
get_sentiments(lexicon = "bing")
#nrc
get_sentiments(lexicon = "nrc")
GoT_stop
GoT_afinn <- GoT_stop %>%
inner_join(get_sentiments("afinn"))
GoT_afinn
GoT_afinn <- GoT_stop %>%
inner_join(get_sentiments("afinn"))
ipcc_afinn <- ipcc_stop %>%
inner_join(get_sentiments("afinn"))
ipcc_stop
ipcc_afinn <- ipcc_stop %>%
inner_join(get_sentiments("afinn"))
ipcc_afinn_hist <- ipcc_afinn %>%
count(value)
# Plot them:
ggplot(data = ipcc_afinn_hist, aes(x = value, y = n)) +
geom_col()
GoT_afinn_hist <- GoT_afinn %>%
count(value)
# Plot them:
ggplot(data = GoT_afinn_hist, aes(x = value, y = n)) +
geom_col()
GoT_afinn_minus_5 <- GoT_afinn %>%
filter(value ==-5)
unique(GoT_afinn_minus_5$word)
# Count & plot them
GoT_afinn_minus_5_n <- GoT_afinn_minus_5 %>%
count(word, sort = TRUE) %>%
mutate(word = fct_reorder(factor(word), n))
ggplot(data = GoT_afinn_minus_5_n, aes(x = word, y = n)) +
geom_col() +
coord_flip()
# What are these '2' words?
ipcc_afinn2 <- ipcc_afinn %>%
filter(value == 2)
GoT_summary <- GoT_afinn %>%
summarize(
mean_score = mean(value),
median_score = median(value)
)
GoT_nrc <- GoT_stop %>%
inner_join(get_sentiments("nrc"))
GoT_exclude <- GoT_stop %>%
anti_join(get_sentiments("nrc"))
# View(GoT_exclude)
# Count to find the most excluded:
GoT_exclude_n <- GoT_exclude %>%
count(word, sort = TRUE)
head(GoT_exclude_n)
GoT_nrc_n <- GoT_nrc %>%
count(sentiment, sort = TRUE)
# And plot them:
ggplot(data = GoT_nrc_n, aes(x = sentiment, y = n)) +
geom_col()
GoT_nrc_n5 <- GoT_nrc %>%
count(word,sentiment, sort = TRUE) %>%
group_by(sentiment) %>%
top_n(5) %>%
ungroup()
GoT_nrc_gg <- ggplot(data = GoT_nrc_n5, aes(x = reorder(word,n), y = n, fill = sentiment)) +
geom_col(show.legend = FALSE) +
facet_wrap(~sentiment, ncol = 2, scales = "free") +
coord_flip() +
theme_minimal() +
labs(x = "Word", y = "count")
# Show it
GoT_nrc_gg
# Save it
ggsave(plot = GoT_nrc_gg,
here("figures","GoT_nrc_sentiment.png"),
height = 8,
width = 5)
